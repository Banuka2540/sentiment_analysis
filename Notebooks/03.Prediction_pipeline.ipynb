{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9dfe31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re \n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c0157b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the punchuations \n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd15329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python_projects\\ML\\sentiment_analysis\\env\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('../static/model/model.pickle','rb') as f : \n",
    "    model = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d32b7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a48e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv(\"../static/model/vocabulary.txt\",header=None)\n",
    "tokens = vocab[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fabf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8a390ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_12764\\912791238.py:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data[\"tweet\"] = data['tweet'].str.replace('\\d+', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(text):\n",
    "    data = pd.DataFrame([text] , columns=['tweet'])\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(remove_punctuations)\n",
    "    data[\"tweet\"] = data['tweet'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE) for x in x.split()))\n",
    "    data[\"tweet\"] = data['tweet'].str.replace('\\d+', '', regex=True)\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))\n",
    "    return data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "009b8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization \n",
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_lst = []\n",
    "    \n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "        \n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] = 1\n",
    "                \n",
    "        vectorized_lst.append(sentence_lst) \n",
    "        \n",
    "    vectorized_lst_new = np.asarray(vectorized_lst, dtype=np.float32)\n",
    "    \n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adc0e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_txt = vectorizer(preprocessed_text,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "741a0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vectorized_text):\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    if prediction == 1 : \n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'postitve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87d0d6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"good great\"\n",
    "preprocessedtext = preprocessing(txt)\n",
    "vectorized_text = vectorizer(preprocessedtext,tokens)\n",
    "prediction = get_prediction(vectorized_text)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89942ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
